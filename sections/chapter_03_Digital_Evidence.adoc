= Digital Evidence 

The aspect of computer forensics that is unique is the nature of digital data. Ultimately, we still conduct an investigation just like a physical crime investigation. We do need to learn and understand the unique challenges of digital evidence. In this chapter we will start with physical aspects and follow logically from hardware to the bits stored inside. There are many reasonable places to start this endeavor, but we will start with binary digits. Binary digits, better known as bits, are the language computers use. All the digital evidence we locate inside of a computer is stored in bits. A bit can have two values, one or zero. A computer takes large strings of 1s and 0s and does that awesome things we all know and love. Photos, emails, text messages and everything else we use computers for is all done in 1s and 0s. Programmers have designed and manipulated those 1s and 0s into brilliant configurations that allows humans to interact with the data without having to deal with any of the machine code. 
When we investigate a hard drive or the content of a cell phone, we are ultimately looking at the 1s and 0s represented as documents, images, emails or other files. One of the most important aspects of digital is that every 1 or 0 is significant. If any single bit is modified, it might render the evidence useless. We must remember and comply with the first rule of investigation, "Do not modify the evidence". 
Have you ever lost a file? Had a power failure that 'ate your homework'? Have you ever experienced the dreaded 'crashed hard drive'? Bits are fragile. We are very fortunate, and all of the pioneers of this field have developed means and methods to protect us as best possible from these disasters. It is important that we use the tools available to us to ensure we stick to our first rule. 

== Spinning Platter Hard Drives 

The most logical place for us to start down the path of digital evidence will start with a physical hard drive. A typical hard drive we might find in the average workplace desktop. It is probably 3.5" or 2.5" spinning platter hard drive (HDD). We will eventually discuss solid state drives (SSD) later in this chapter, but for starting concepts, we are starting with traditional hard drives. 

When we start our investigation, we seize a physical desktop. We take the desktop back to our lab and extract the physical HDD. We would hook our HDD up to some write block device and use specialized software to make a copy. The software, such as Access Data FTK Imager (R), is designed to make a bit-by-bit copy known as a bit stream image. The software verifies that each bit is the same in the copy as the original. The file(s) created during the bit stream image process typically included multiple verification mechanisms and fail-safes to ensure that all the bits are identical. 
We take our bit stream image and add it into an examination suite to look at the contents. We will examine this process in more detail in a subsequent chapter. We just need to know there is a method to take the physical evidence and copy the bits without making any changes to the evidence. 
How a spinning platter hard drive works is an important aspect to investigating a computer and knowing how data is stored and retrieved from a HDD. The way a HDD works has some aspects that apply to all types of storage and key forensic impact. We need to start with a description of the physical aspects of a HDD. 
Inside of a HDD you will find one or more physical discs known as platters. They are typically plastic or ceramic disks coated with a ferrous coating. The center of the disc is a motor that spins the disks at rates of between 4,500 and 12,000 rotations per minute depending on the model of the drive. The drive has an arm that moves across the surface. This arm is mechanical in nature and has a read/write heads on the end of the arm on both sides of each disk. The arm moves to the appropriate location to access the correct physical spot to read or write as needed. 
The disks have a series of magnetic tracks, like concentric circles, and dividers placed on the disks to hold bits. The areas place on the disks during the manufacturing process are known a sector. Sectors are 512 bits for drives up to 2TB in capacity and 2048 bits for drives larger than 2TB. The bits are recorded as a positive or negative charge and written to the correct sector. The drive has a chip to associate a physical location to each sector. 

image::images/disk1.png[Image of a disk structure]

=== File Systems 
The operating system of the computer, for us we are using Windows 7(R), does not interface directly to the hard drive for reads and writes for normal operations. The drive is formatted with a file system. The files system acts as an intermediary between the physical disk and the operating system. In Windows (R) the default file system is NTFS. There are some aspects of NTFS that are unique, but we will start with the general 'most file systems' and discuss NTFS specifics as needed. 
The file system tracks files. Formatting a HDD creates clusters. Clusters are logical and where possible, physical grouping of sectors. 4 kilobit (kb) clusters are very common amongst most file systems and the default for NTFS for drives under 2TB in size. The size of a cluster can be customized during the format process ranging from 512 bits to 64 kb in NTFS. The formatting process creates a table of clusters and what is stored in that specific cluster. The files system communicates to the HDD to read or write to a specific cluster. The command comes to the HDD to start at a specific sector and the drive moves the arm to the correct physical location. 
You may have noticed when you format a hard drive, the available size is less than the physical drive size. When a drive is formatted with a file system, that file system requires space to track each location and what is in that specific spot, even when empty. Additionally, the file system can record information specific to the file such as the date and time the file was created, lasted accessed, last modified and even in NTFS which user account owns the file. These supplemental pieces of information, created and maintained by the file system, is called metadata and can be invaluable to investigators. 

The useful information that will help us prove or disprove the allegations we are investigating lies inside the files stored on the HDD. The physical evidence gives us access to the bits. The bits give us files. The files contain the artifacts that we can interpret and report. Hopefully you are super sharp, and you are thinking, "Hey! What about files that are larger than 64 kb, the maximum size of a single cluster in NTFS?". The answer is easy! We use more than one cluster. The HDD and the file system break the file into fragments that fit into clusters and the file system tracks each fragment. When the file is being written to the drive into multiple clusters it is common for the clusters to be in physically separated areas. This by product of writing a large file into physically separated clusters is known as fragmentation. Fragmentation can slow down the read or write process significantly. Most operating systems have a utility to try and re-arrange files, so they are less fragmented. When we look at this from a forensic perspective, it is neither a positive or a negative, merely a fact we must be aware happens. 

Sectors and clusters functionality and how file systems interact with the physical drive create some interesting forensic possibilities. The most common and useful quirk of hard drives is deleted files. When a user deletes a file and in Windows(R) empties the Recycle Bin, the file is not gone. You have likely seen or heard of undeleting files. This concept of restoring deleted files in the forensic world is known as data carving. The process of deleting a file is the key to understanding how it is possible. This process is in general identical for all operating systems and file systems. When the operating system deletes a file, it tells the file system the file is no longer needed. The file system then marks the cluster(s) as empty and available to be written to again as needed. Clusters that are not associated with a file are unallocated. The file system does not do anything with the actual cluster contents. Data carving looks at each cluster trying to identify files that might be physically present, but not listed in the file system. The results of data carving can provide great results or nothing of value. 

The file system clustering system also has issues surrounding contents of a cluster. The most file systems, including NTFS, only track one file or fragment of a file per cluster. This leaves the possibility of empty space inside of a cluster. If you save a 5 kb file on a hard drive with 64 kb clusters, 59 kb of the cluster is unused. This unused space is known as slack space. If we also consider that a deleted file is not overwritten or removed, that slack space could contain 59 kb of another file. It is possible that the remnant of a partially overwritten file might contain useful information that might be evidence to support the allegations we are investigating. 
NTFS has some unique characteristics. The study of the forensic aspects of NTFS warrants a complete textbook to itself as a standalone topic. There are some things we must know for our introductory purposes. NTFS is a journaling file system. This simply means it tracks changes in a log. This log file is $MFT and sits on the root of the drive. Unfortunately, we cannot just open it up and read it as Windows(R) is running. If we could, it wouldn't be very people friendly to look at the contents. This journalling aspect helps the process of data carving to be more successful. The contents of $MFT indicates recent writes and deletes along with where the files are or were. NTFS also handles small files uniquely. The file can be stored inside $MFT if it is a small file. This prevents a cluster from being allocated to a small file and wasting space as each cluster can only be associated with one file or fragment of a file. 

=== Data Destruction 
It is also important we discuss data destruction in this section. If a HDD is physically damaged the normal read process is not possible. Specialized equipment might be able to read data from the platter of a disk that has a bullet hole in it or a platter that is bent. The data recovered from a physically damaged disk might not contain any intelligent content or it might recover evidence that supports the allegations. This is an extraordinary effort, but plausible for the right scenario. It is not realistic for an average investigator to be able to attempt to recover data from a damaged drive. The cost and time involved in attempting to recover data from a damaged disk prevents most organizations from attempting to use damaged HDD as evidence. 
A common method to erase HDDs is to use a powerful magnet to remove the magnetic tracks that separate and contain the positive or negative charges that represent 1s and 0s. This process is known as degaussing. If the magnet is powerful enough the data is gone, and the drive can no longer retain any data. 

Deleting data can be accomplished by overwriting the current data. This is for all practical purposes unrecoverable with a single over-write. The ability to see the last seven states of a bit can be achieved if the platter is examined with an electron microscope. It is theoretically possible to read all seven previous states of all bits on a drive and reconstruct any data that was on the drive for the past seven writes. This process is not realistic because of the resources needed to accomplish this task and find useful information is not possible. The process of reads all the bits in each of the seven previous states then attempting to reassemble them in order is mathematically unachievable with modern computing power. It is however considered by entities with very sensitive data, such as military secrets, to be a possibility. As a result of this there are data erasure standards and utilities that will over-write each bit seven times to ensure that no data can ever be recovered. All methods of examining that do not include the use of an electron microscope, a very expensive piece of equipment, over-writing a bit one time makes it truly deleted. 

Data destruction is a common occurrence on modern drives without users knowing that it has occurred. Defects in disk surface is a common problem. The precision of a physical disk with platters is phenomenal. It can read, write and move to .005mm at speeds of 10,000 rpms! Drives have trillions of bits. This is truly amazing. But the manufacturing process is not perfect and areas on the platters might not be high enough quality to endure that type of environment. Bad sectors happen on modern drives regularly. When a drive cannot read or write to a specific sector, it will identify that as a bad sector and substitute it with one of many spare sectors on the drive. Most drives ship with as much as ten percent extra space reserved for replacing bad sectors. These spare sectors are not accessible by normal means and are not part of the calculated available or used space in a drive. This technology is known as S.MA.R.T technology. It doesn't change our approach but know that the tools we will use address these bad sectors. The software will attempt to read all accessible areas. 
Solid State Drives 
Solid state drives (SSD) have most of the same aspects as a spinning platter drive. Instead of platters, it has memory cells etched in silicon with a membrane that allows the charge to pass into the cell. This membrane has a limited life span and can deteriorate with use. Most modern drives can be written constantly for years before they fail, but it is a consideration in some technological respects. The cells are grouped together physically and logically. SSDs have sectors and is formatted by a file system into clusters. They are faster in read and writing times and less prone to mechanical failure as there are no moving parts. The cell and membrane aspect does create one phenomenon, known as write amplification, that does have a potential impact on digital forensics. 

Over time SSD cells fill up with data. As the data is deleted by the file system the charges remain in the storage cells, just like on a spinning platter drive. When the drive attempts to write to an area that has remnants of previous files, it must negate what is there to a neutral state before it can write the data desired. This effect is compounded in multi-layer storage because charges may have to be submitted several layers deep before it can write. The speed of drives slows dramatically the longer it is used. SSD manufacturers developed an ATA protocol standard to address this phenomenon. The protocol is known as Trim support. Most modern solid-state storage, including storage in phones and tablets, support Trim. 
Trim support initiates a request from the operating system to the drive to clean up unallocated space before it is needed again. This effectively erases any files that we previously would have been able to successfully use data carving to recover. The implementation of this is non-standard at the operating system level and can occur at any time. Once the command is sent to the SSD it is executed 'as drive activity is available'. It is possible that you might remove an SSD from a suspect computer, hook it to a write blocker and begin to copy the contents as the Trim is activated. It is highly unlikely this will happen, but deleted files tend to be gone for good quickly in SSDs where Trim support is enabled, and the operating system supports Trim. 
Hashing Functions 
Now that we have discussed where the 1s and 0s are, how we access them and some of the quirks of data on drives, we need to go back to rule number one, 'Don't modify the evidence'. We are fortunate that there is an established technology in use by investigators today that helps prove that the 1s and 0s are unmodified. The technology is known as hashing functions or hash functions. The most common hash function used in digital forensics is the MD5 hashing function. A hashing function performs a mathematical manipulation of data in fixed lengths. MD5 calculates 128-bit blocks. It is an iterative process that starts with a fixed length value of 128 bits, does bit level math and generates a result of 128 bits. The result is then used as the value to compare to the next 128-bit block of data that is being hashed. That result is used to compute the next block. The process repeats until the end of the file. The final mathematical calculation will add zeros to the end of the data until it is equal to 128 bits. The result is 128-bit string that is unique to that file. A practitioner can verify that all the 1s and 0s are identical between the original and the copy (or before and after) if the values match. 
Hashing functions are one-way functions. This means that you cannot recreate or predict the original content. The result of a hash function will always give the same result if you put in the same input. A single modification of one bit or character give a dramatically different 128-bit value. The results are not predictive. Any length of data can go into the function and will receive a unique 128-bit result. We can perform a hash value calculation on an 8 TB hard drive or a 6 KB digital image. Both will have 128-bit values that are unique. 

Mathematically it is possible for two different chunks of data to have the same resulting hash value. This is known as a collision. There are only 340 billion-billion-billion-billion possible MD5 hash values. If I have 340 billion-billion-billion-billion and one files, two will have the same MD5 hash value. Forensic software and investigators also have used SHA-1 hashing function to calculate a second unique value for each file. It is mathematically infeasible for two files to have collisions with both algorithms as SHA-1 is 160-bits and MD5 is 128-bits. Sadly SHA-1 has recently been cracked by a group of researchers and they have developed a method to manipulate the content of data and generate the same SHA-1 value, so it is no longer considered a trustworthy hashing function. It is likely another hashing function will replace it soon. Identical hash values verify that all the bits of both data items are identical. This concept is proven and accepted as fact in a court of law. 
Ultimately all the 1s and 0s are what we work on. What we see, what we collect, what we interpret and what we present is in a far friendlier format, files. The key to every investigation is to locate files, look at what is inside the files and explain it to our requestor what is present in the drive. 
Files and how they are composed is dependent on the type of file or the type of application that use the files. A digital image might have one of many formats. Each of those formats is unique. The same would be true for text documents or audio clips. The formatting or type of file in Windows(R) is often identified by extension. Extensions allow Windows(R) to associate a type of file with a specific application. All files have data near the beginning of the file, known as file headers, that identifies the type of file that it is. Most other operating systems use file headers to associate a file type with an application. 
Learning which files contain the artifacts we need to locate and interpret to provide evidence to the requestors is the key to a successful investigation. In subsequent chapters we will look at some specific files and if you are following with the hands-on labs, you will have the opportunity to learn some useful files and their contents. 
